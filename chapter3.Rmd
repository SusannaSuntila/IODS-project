
# Logistic regression


```{r}
date()
```


## Read the data

```{r}
library(tidyverse)
# read in the data that was created
alc <- read.csv(file.path(".", "data", "alc.csv"))

# print names of the variables
colnames(alc)
```



This data set is constructed from a secondary school student questionnaire of Portuguese schools. As the names of the variables indicate, the questions cover topics such as school and studies, but have also social and demographic aspects. The alc data set is combined from two data sets dealing with the students' performance in math and Portuguese language.


## Relationships between high/low alcohol consumption


The binary variable **address** is an interesting one, I would predict that when living in urban areas high alcohol use would be more probable, as there are more options to use alcohol than for students living in rural areas.


Another variable that I want to look at is the **studytime** one (weekly study time, divided into 4 groups, where 4 is the highest amount spent in studying), to see if spending more time studying is negatively related to high alcohol use, as the student is spending more time with studies and is possibly more committed to school.


I would hypothesize also that **goout** variable, telling how much the student goes out with friends (1-5 scale where 5 is very high) is positively linked to high alcohol use, as alcohol is usually a socially related issue.


Lastly I wanted to include the more continuous variable **absences**, which measures the number of school absences (0-93). I would hypothesize that more absences are positively linked to high alcohol use, as drinking a lot might affect the student's attendance at school.



## Explore variables' distributions and relationships with alcohol consumption


First the **address** variable


```{r}

library(ggplot2)

# set the background white
theme_set(theme_bw())

# bar plots of address variable
g1 <-  ggplot(data = alc, aes(x = address, fill = high_use)) + 
  geom_bar() +
  theme(legend.position = "none") +
  scale_fill_manual(values = c("paleturquoise3", "paleturquoise4"))

g2 <- ggplot(data = alc, aes(x = address, fill = high_use)) + 
  geom_bar(position = "fill") +
  ylab("proportion") +
  scale_fill_manual(values = c("paleturquoise3", "paleturquoise4"))

# combine the two plots
library(patchwork)
g1 | g2


```


As can be expected, most of the students live in urban areas, and so more people have high use of alcohol levels in urban areas, but contrary to what I thought relatively more people have high use of alcohol in rural areas.


Next the **studytime** variable:


```{r}

# studytime variable
g3 <-  ggplot(data = alc, aes(x = studytime, fill = high_use)) + 
  geom_bar() +
  theme(legend.position = "none") +
  scale_fill_manual(values = c("plum3", "plum4"))

g4 <- ggplot(data = alc, aes(x = studytime, fill = high_use)) + 
  geom_bar(position = "fill") +
  ylab("proportion") +
  scale_fill_manual(values = c("plum3", "plum4"))

# combine the two plots
library(patchwork)
g3 | g4


```


As I thought, less studytime has higher proportion of students who have high use of alcohol. This is clear for both absolutely and proportionally.


Next the **goout** variable:


```{r}
# the going out variable

g5 <-  ggplot(data = alc, aes(x = goout, fill = high_use)) + 
  geom_bar() +
  theme(legend.position = "none") +
  scale_fill_manual(values = c("palevioletred3", "palevioletred4"))

g6 <- ggplot(data = alc, aes(x = goout, fill = high_use)) + 
  geom_bar(position = "fill") +
  ylab("proportion") +
  scale_fill_manual(values = c("palevioletred3", "palevioletred4"))

# combine the two plots
library(patchwork)
g5 | g6

```


Here the high use of alcohol increases with the amount of going out with friends, and the pattern is very clear.


And lastly the **absences** variable:

```{r}
# absences
g7 <- ggplot(data = alc, aes(x = absences, fill = high_use)) + 
  geom_bar() +
  theme(legend.position = "none") +
  scale_fill_manual(values = c("pink3", "pink4"))

g8 <- ggplot(data = alc, aes(x = absences, fill = high_use)) + 
  geom_bar(position = "fill") +
  scale_fill_manual(values = c("pink3", "pink4")) +
  ylab("proportion")

# combine the two plots
library(patchwork)
g7 | g8


```


Here it is also clear that increase in absences is linked to an increase in high use of alcohol as well, but there are also some outliers with few students who have a very high amount of absences.


Looking at the absences variable closer with a box plot:


```{r}

# box plot of absences with color by address
ggplot(data = alc, aes(x = high_use, y = absences, col = address)) + 
  geom_boxplot() +
  scale_color_manual(values = c("violetred", "violetred4"))


```


The median of absences is the same whether student is form rural or urban area when there is no high use of alcohol, but the median for absences is slightly higher for students from rural areas if they belong to the high use of alcohol group.


Next few cross-tabulations. First I wanted to add a table that includes address, the mean of going out and of course high use of alcohol.


```{r}

# table of address, high use of alcohol and the mean of going out
alc %>% group_by(address, high_use) %>% summarise(count = n(), mean_goout = mean(goout))


```


The mean of going out increases quite a lot when the alcohol use is high for both rural and urban area students. The mean of going out in both cases of alcohol use is higher for students who live in urban areas compared to rural area students, as would be expected.


Another cross-tabulation of the mean of studytime and mean of absences with regards to alcohol use:


```{r}

# table of address, high use of alcohol and the mean of going out
alc %>% group_by(high_use) %>% summarise(count = n(), mean_studytime = mean(studytime), mean_absences = mean(absences))


```


Those students who have high use of alcohol also have lower mean of studytime and higher mean of absences compared to those who do not have high use of alcohol.




## Logistic regression of the chosen variables


```{r}

# simple model with only the absences as an explanatory variable
model <- glm(high_use ~ absences, data = alc, family = "binomial")

#summary of the simple model
summary(model)

####

# model with all the chosen variables: absences, studytime, goout and address
model1 <- glm(high_use ~ absences + studytime + goout + address, data = alc, family = "binomial")

# print out a summary of the model
summary(model1)

# print out the coefficients of the model
coef(model1)

# compute odds ratios (OR)
OR <- coef(model1) %>% exp

# compute confidence intervals (CI)
CI <- confint(model1) %>% exp()

# print out the odds ratios with their confidence intervals
cbind(OR, CI)


```


I looked at first a simple model, where absences was the only explanatory variable, and the AIC was 438.52. After adding the three other variables, the AIC had decreased to 381.44, so adding the other variables has improved the model.


When looking at the summary of the fitted model with all the chosen variables, all the coefficients are statistically significant at the 5 % level. As the exploration of the variables earlier implied, the relationship is positive with absences and goout, so increase in these variables will increase the odds of the student having high use of alcohol. Studytime and address on the other hand decrease the odds of having high use of alcohol.


Looking at the coefficients more closer, absences has an odds ratio of 1.069, meaning that a unit increase in absences increase the odds of the student having high use of alcohol by 6.9% keeping other variables constant, and the confidence interval is between 2.5% and 11.97%. This isn't as large an effect, as I might have expected.


Studytime has a coefficient that is less than one, 0.55, so when studytime increases by one more unit, it decreases the odds of the student having high use of alcohol by 45% when other variables are constant, and the 95% CI is 61% - 24% decrease in odds. Studytime has an opposite effect when increasing, compared to absences.


The goout variable has an odds ratio of 2.125, meaning that a unit increase in goout increases the odds of the student having high use of alcohol by 112.5% again adjusting for the other variables in the model. The 95% CI is 68.8% - 171%. So going out has quite a large effect, which was apparent when plotting it in the beginning.


The address variable has an odds ratio of 0.48, meaning that if the student lives in an urban area, it decreases the odds of the student having high use of alcohol by 52%, when adjusting for the other variables. The negative effect has a 95% CI between 74% - 13%. This is quite surprising as in the beginning I wasn't even sure of the direction of the effect.



## Explore the predictive power of you model


First a 2x2 cross tabulation of predictions versus the actual values:


```{r}
# fit the model
model1 <- glm(high_use ~ absences + studytime + goout + address, data = alc, family = "binomial")

# predictions
library(dplyr)
alc <- mutate(alc, probability = predict(model1, type = "response"))
alc <- mutate(alc, prediction = probability > 0.5)


# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction)

# initialize a plot of 'high_use' versus 'probability' in 'alc'
ggplot(alc, aes(x = probability, y = high_use, col = prediction)) +
  geom_point() +
  scale_color_manual(values = c("skyblue2", "skyblue4"))

```


This model predicts high use incorrectly for 22 students, and low use incorrectly for 63 students.


Next the the total proportion of inaccurately classified individuals, the training error.


```{r}
# define a loss function (mean prediction error)

loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

# call loss_func to compute the average number of wrong predictions in the (training) data
loss_func(class = alc$high_use, prob = alc$probability)


```

The training error is 0.2297, so on average ~23% of the predictions are wrong. The training error is below 0.5, so it is better than randomly guessing.


## Perform 10-fold cross-validation on your model


```{r}

#K-fold cross-validation, K=10
library(boot)
cv <- cv.glm(data = alc, cost = loss_func, glmfit = model1, K = 10)

# average number of wrong predictions in the cross validation
cv$delta[1]


```

One set of the 10-fold cross-validation gives the prediction error of 0.2378, so 23.78% of the predictions are wrong. This is slightly smaller than the model in the exercise set had, 0.26, so the model that I have used has a bit better test set performance.







